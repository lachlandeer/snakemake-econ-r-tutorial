[
["index.html", "Reproducible Research Workflows with Snakemake and R Prerequisites", " Reproducible Research Workflows with Snakemake and R An Extended Tutorial for Economists and Social Scientists Lachlan Deer Julian Langer 2019-02-04 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: "],
["intro.html", "Chapter 1 Motivating &amp; Rationale 1.1 A Case for Reproducibility 1.2 What is Snakemake &amp; Why Should you use it? 1.3 Why R? 1.4 Working Example: Replicating Mankiw, Romer and Weil’s 1992 QJE 1.5 The way forward", " Chapter 1 Motivating &amp; Rationale 1.1 A Case for Reproducibility 1.1.1 How far to go in the quest for reproducibility? 1.2 What is Snakemake &amp; Why Should you use it? 1.3 Why R? 1.4 Working Example: Replicating Mankiw, Romer and Weil’s 1992 QJE Throughout our tutorial we are going to use a running example to illustrate the concepts we discuss. 1.5 The way forward For the purpose of this tutorial we will focus on replicating the following aspects of the MRW paper:1 Regression Tables 1 and 2: Estimating the Textbook- and Augmented Solow Model Figure 1: Unconditional Versus Conditional Convergence To replicate these we will need to proceed as follows: Perform some data management Prepare the data before we run regressions Do some analysis. For example, run regressions for: Different subsets of data Alternative econometric specifications Turn the statistical output of the regressions into a tabular format that we can insert into a document Construct a set of graphs Integrate the tables and graphs into a paper and a set of slides (optional) We hope that these 5 steps look familiar - as they were designed to represent a simplifed workflow for an applied economist or social science researcher. Before proceeding to understanding how to use Snakemake and R to construct a reproducible workflow, the next chapter first takes a deeper dive into the a protypical way to set up a research project on our computer. Exercise: Your own project’s steps Think about a project you are working on or have worked on in the past (it may be a Bachelor or Master’s thesis or a recent / active research project). Does your project fit into the 5 steps we described above? If not, what would you modify or add to our 5 steps? (Do you think this would destroy the general principles we will encourage over the next chapters?) A complete replication using the concepts presented in this tutorial is available here↩ "],
["part-i.html", "PART I", " PART I "],
["project-organization.html", "Chapter 2 Project Organization 2.1 Project Structure I: Separating Inputs and Outputs 2.2 Project Structure II: Separating Logical Chunks of the Project 2.3 Project Structure III: Separating Input Parameters from Code", " Chapter 2 Project Organization 2.1 Project Structure I: Separating Inputs and Outputs Structuring our project and the locations of files is an important concept. Let’s look at the structure of our project’s folder. Open a terminal and change into this directory cd YOUR/PATH/TO/snakemake-econ-r-student And list the subdirectories of the main directory ls -d */ We see the following folder structure ./ |- src/ |- out/ |- log/ |- sandbox/ We recommend the following structure for any project: Root Folder src folder for input files out folder for output files a log folder to store computer logs a sandbox folder that gives us a ‘safe place’ to develop new code We discuss each of these in turn. 2.1.1 The Root Folder TBD 2.1.2 The src folder TBD 2.1.3 The out folder TBD 2.1.4 The log folder 2.1.5 Exploring the Full Structure of the MRW Replication Project Now, let’s look at all contents of this main projects directory: ls -F . We see the following folder structure ./ |- src/ |- out/ |- log/ |- sandbox/ | README.md | Snakefile Notice that there are no instances of: (i) scripts, (ii) files containing content of the paper or slides (iii) something else we haven’t thought of yet Instead, there are only two files, a README.md and a file called Snakefile. TODO: explain these two files 2.2 Project Structure II: Separating Logical Chunks of the Project As we have mentioned above, to keep our project’s structure clean, we want to keep all the computer code inside the src directory. Let’s have a look at the content of src. ls -F src/ We see the following output: ./ |src/ |- data/ |- data-management/ |- data-specs/ |- analysis/ |- model-specs/ |- lib/ |- figures/ |- tables/ The type of content we expect in each file is: TBD 2.2.1 Exploring the Structure of the MRW Replication Subdirectories We begin our exploration of the project by looking at the folders that appear to be related to the data. If we look inside the data directory ls -F src/data/ mrw.dta That is, our data/ directory contains the project’s original data set. Note that in more extensive projects, the data/ subfolder would typically have more than one data set. For example: dataset1.dta dataset2.dta dataset3.csv TBD - aside on file endings. Further, your data folder may even contain further subdirectories that organize data further ./ |src/ |- data/ |- data-provider-a/ |- dataset1.csv |- dataset2.csv |- data-provider-b/ |- dataset3.txt |- dataset4.txt If we now turn to the data-management directory, we can explore it’s contents too: ls -F src/data-management/ rename_variables.R gen_reg_vars.R TODO: meaningful filenames Note two different ways to name files Exercise: Exploring the Remaining Subdirectories TBD 2.3 Project Structure III: Separating Input Parameters from Code Next we look at the somewhat mysteriously named data-specs folder. And if we explore the folder’s contents: ls -F src/data-specs/ subset_intermediate.json subset_nonoil.json subset_oecd.json Again, the file names are somewhat meaningful on their own - they appear to be some way of subsetting data (selecting some rows). If we look inside one of these files: cat src/data-specs/subset_oecd.json { &quot;KEEP_CONDITION&quot;: &quot;oecd == 1&quot; } We see an a variable KEEP_CONDITION which is storing a string &quot;oecd == 1&quot;. TBD: Why have we done this? See below. 2.3.1 Exploring Parameter Separation in the MRW Replication Project "],
["initial-steps-with-snakemake.html", "Chapter 3 Initial Steps with Snakemake 3.1 Starting a Research Project 3.2 The Beginning of a Snakefile 3.3 Rule Structure 3.4 Our First Rule 3.5 Creating a Second Rule 3.6 Clean Rules", " Chapter 3 Initial Steps with Snakemake 3.1 Starting a Research Project We are now ready to get started working with the code and data to build a fully reproducible pipeline. In Chapter XX we described a simplified research workflow to be: Perform some data management Do some analysis Turn the output of the analysis into a tabular format Construct a set of graphs Integrate the tables and graphs into a paper and a set of slides (optional) We are going to start at the beginning with data management. Recall that we have the following files in our data management subdirectory, src/data-management: rename_variables.R gen_reg_vars.R We will need to run each of these scripts sequentially. First we want to run the script rename_variables.R to tidy up the variable names in our data set. Second, gen_reg_vars.R will create the some additional variables in our data that will be needed to run some regressions in later steps. Over the next few sections we are going to build up 2 rules, one for each file, that will execute these scripts and deliver output. 3.2 The Beginning of a Snakefile We are going to put the collection of rules that build our project into a file. We can then use the Snakemake to execute these rules and build our project. The set of rules we want to construct are going to go into the file called Snakefile - which is the name of a file that Snakemake will look into by default to execite a project. Lets open the file called Snakefile in the project’s main directory. When you open it it should look as follows: # Main Workflow - SOME PROJECT # # Contributors: YOUR NAME(S) Note that the amount of structure we have here is not totally necessary. However, good structure will make understanding easier later. Let’s go through what we see. The first lines of code are comments, to help us navigate a little and understand what we are looking at. The very first line tells us that this is a project workflow, and then tells us what the particular project is. The second line tells us who contributed to this file. This can be useful so we know who to contact with questions. You should do update the name of the project, and add your name to the list of contributors. For us, the top 2 lines becomes: # Main Workflow - MRW Replication # # Contributors: @lachlandeer, @julianlanger The next few lines are: # --- Main Build Rules --- # ## To be constructed These are more comments. We are using the # --- Something --- # notation to break up the code into logical blocks. It is in this block that we will assemble the rules on which our project will be built. 3.3 Rule Structure A Snakefile is a collection of rules that together define the order in which a project will be executed. In our Snakefile we will start to assemble rules under the # --- Main Build Rules --- # section to keep things tidy. Each rule can be thought of as a recipe that combines different inputs, such as data and and R script together to produce one or more output(s). The key components we are going to use to construct a rule are: a name for the rule, the list of inputs the list of outputs produced a shell command that tells snakemake how to combine the inputs to produce a outputs. Snakemake expects these components to be provided in a particular way so that it knows what to do with the information you provided. We are going to specify rules in the following format: rule rule_name: input: input_name1 = &quot;PATH/TO/input_one&quot;, input_name2 = &quot;PATH/TO/input_two&quot; output: output_name1 = &quot;PATH/TO/SAVE/output_one&quot;, output_name2 = &quot;PATH/TO/SAVE/output_two&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; We can have as many inputs and outputs as we need to have per rule. Each input and each output are given names, for example input_name1 which take the value to the file path and name of the file. It is important to wrap each of these paths into quotations, and to separate each of the multiple inputs and outputs with a comma. 3.4 Our First Rule 3.4.1 Constructing the Rule As mentioned above, we will start with the data management step. First script to run is rename_variables.R which is located in the data management subdirectory. This is a simple script that renames some variables for us to be easier to understand. We can then start our snakemake script by adding this script as an input: rule rule_name: input: script = &quot;src/data-management/rename_variables.R&quot;, input_name2 = &quot;PATH/TO/input_two&quot; output: output_name1 = &quot;PATH/TO/SAVE/output_one&quot;, output_name2 = &quot;PATH/TO/SAVE/output_two&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; Next, we want to add any additional inputs and also specify any outputs that the file produces. We have set up all R scripts in this example to provide us with ‘help’ so that we know what we might need to add. To find out what inputs are required and what outputs are produced, we use the --help flag when calling the file with R: $ Rscript src/data-management/rename_variables.R --help And the following output is produced: Usage: src/data-management/rename_variables.R [options] Options: -d CHARACTER, --data=CHARACTER stata dataset file name -o CHARACTER, --out=CHARACTER output file name [default = out.csv] -h, --help Show this help message and exit This suggests the script needs … We update our rename_variables as: rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; Next we provide a recipe telling snakemake how to mix the inputs to create the outputs: rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data}&quot; We can now try and run snakemake to execute this rule … $ snakemake Stuff happens … 3.4.2 Analysing Output We can look into our output directory to see if anything has happened: $ ls out/data/ which yields mrw_renamed.csv Our file has been created as we expected. Try and run snakemake again $ snakemake and we see the following output: Building DAG of jobs... Nothing to be done. Why? Snakemake provides the a summary option which tells us what is going on: snakemake --summary The output is: Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_renamed.csv Thu Jan 10 20:31:08 2019 rename_vars - ok no update Explain what this tells us … Suppose we updated one of the inputs … $ touch src/data-management/rename_variables.R and then look at the summary from snakemake: $ snakemake Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_renamed.csv Thu Jan 10 20:31:08 2019 rename_vars - updated input files update pending What this means? Run snakemake to build the output: snakemake Exercise: Deleting Output Delete the output out/data/mrw_renamed.csv. Run snakemake --summary and explain the output it produced. 3.5 Creating a Second Rule The second step in our data management is to create some variables we will use in our regression analysis. The script gen_reg_vars.R in the src/data-management folder does this for us. We are going to build a rule called gen_regression_vars to do this in Snakemake. Let’s see what the script expects to be passed: $ Rscript src/data-management/gen_reg_vars.R --help Usage: src/data-management/gen_reg_vars.R [options] Options: -d CHARACTER, --data=CHARACTER a csv file name -p CHARACTER, --param=CHARACTER a file name containing model parameters -o CHARACTER, --out=CHARACTER output file name [default = out.csv] -h, --help Show this help message and exit So we need to provide: to provide the output … Let’s create this rule: rule gen_regression_vars: input: script = &quot;src/data-management/gen_reg_vars.R&quot;, data = &quot;out/data/mrw_renamed.csv&quot;, params = &quot;src/data-specs/param_solow.json&quot;, output: data = &quot;out/data/mrw_complete.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --param {input.params} \\ --out {output.data}&quot; What will Snakemake want to do next? Let’s use the summary option to see … $ snakemake --summary Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_complete.csv - gen_regression_vars - missing update pending out/data/mrw_renamed.csv Fri Jan 11 13:40:07 2019 rename_vars - ok no update Explain what this means Let’s run snakemake to build our new file: $ snakemake When we look at our output directory: $ ls out/data/ mrw_complete.csv mrw_renamed.csv So we see that our data set has been built. Exercise: Creating Rules The MRW paper estimates the Solow model for three subsets of data. You need to create rules to do estimate the Solow model for each of these data sets. The R script src/analysis/estimate_ols.R will estimate a OLS model for a given dataset when you provide the necessary inputs. What inputs do you need to provide? What outputs will be produced? Write Snakemake rules to estimate the solow model for each subset of data. 3.6 Clean Rules So far, we have built up our Snakefile to: Clean data Run a regression model on different subsets of data As we continue to extend our Snakefile in the coming chapters we might want to be able to delete all of the produced outputs, and see if we can rebuild our project from the first step. One way to do this would be to go to our terminal window and enter the following command each time: $ rm -rf out/* Instead of doing this each time, we can integrate this cleaning of computer produced outputs into our Snakefile. We can create a rule called clean that stores the shell command from above: rule clean: shell: &quot;rm -rf out/*&quot; Note that this rule has no inputs or outputs. To use this rule, we enter the following into our terminal: $ snakemake clean Notice that to use the clean rule we had to call the rule name, clean, explicitly. Now if we look out the output of running the summary call with snakemake, we see the following output: snakemake --summary Building DAG of jobs... output_file date rule version log-file(s) status plan out/analysis/model_solow_subset_intermediate.rds - inter - missing update pending out/analysis/model_solow_subset_nonoil.rds - nonoil - missing update pending out/analysis/model_solow_subset_oecd.rds - oecd - missing update pending out/data/mrw_complete.csv - gen_regression_vars missing update pending out/data/mrw_renamed.csv - rename_vars missing update pending Which reveals snakemake’s plan the next time its run will be to build all outputs. Exercise: Creating Cleaning Rules So far we have written a cleaning rule that deletes everything in the out/ directory. Construct rules that would separately clean the out/data/ and out/analysis subdirectories. Why might we want to do this? "],
["pattern-rules.html", "Chapter 4 Pattern Rules 4.1 Where we are now? 4.2 Wildcards 4.3 The expand() function 4.4 Expanding Multiple Wildcards", " Chapter 4 Pattern Rules 4.1 Where we are now? Your Snakefile should look something like this: ## Snakemake - MRW Replication ## ## @yourname # --- Build Rules --- # rule solow_intermediate: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_intermediate.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_intermediate.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule solow_nonoil: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_nonoil.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_nonoil.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule solow_oecd: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_oecd.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_oecd.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule gen_regression_vars: input: script = &quot;src/data-management/gen_reg_vars.R&quot;, data = &quot;out/data/mrw_renamed.csv&quot;, params = &quot;src/data-specs/param_solow.json&quot;, output: data = &quot;out/data/mrw_complete.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --param {input.params} \\ --out {output.data}&quot; rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data}&quot; # --- Clean Rules --- # rule clean: shell: &quot;rm -rf out/*&quot; This is good progress, but if we look at the solow_ rules we see that there is quite a lot of duplication: Detail the duplication here 4.2 Wildcards Ideally, we want our Snakefiles to feature the miniumum amount of duplication possible (Why?). The three solow_ rules can be collapsed into one rule if can create a variable, for example iSubset, that can iterate through the three .json files that contain the subset filters. That is, we want to create a rule solow_model that can do the work that solow_nonoil, solow_oecd and solow_intermediate currently do. In Snakemake, these variables are called wildcards. The format of this rule will be: rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; We wrapped our wildcard iSubset in curly parentheses so that Snakemake knows that we will want to substitute the name of one of the subsets into this value. This is conceptually similar to what we have done in our shell commands. We can now try and run our updated Snakefile: $ snakemake Building DAG of jobs... WorkflowError: Target rules may not contain wildcards. Please specify concrete files or a rule without wildcards. What has happened? Snakemake will not execute a rule that contains wildcards.2 What we will do is create another rule, run_solow that will not contain wildcards … rule run_solow: input: nonoil = &quot;out/analysis/model_solow_nonoil.rds&quot;, oecd = &quot;out/analysis/model_solow_oecd.rds&quot;, intermediate = &quot;out/analysis/model_solow_intermediate.rds&quot; rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; Explain what happens here… There’s more work we can do to reduce duplication. Look at the rule run_solow: rule run_solow: input: nonoil = &quot;out/analysis/model_solow_nonoil.rds&quot;, oecd = &quot;out/analysis/model_solow_oecd.rds&quot;, intermediate = &quot;out/analysis/model_solow_intermediate.rds&quot; 4.3 The expand() function Each of these inputs listed above have similar structure, with only the name of the subset of data we are using changing. We can use another feature of Snakemake to simplify this rule. Snakemake has an expand() function that can accept a wildcard and replace it with a set of specified values in an iterative manner. In our case, we want to use the expand function to accept the {iSubset} wildcard, and replace it with the values ‘nonoil’, ‘oecd’ and ‘intermediate’ one at a time. To proceed we need to do two things: Create a list, DATA_SUBSETS, that contains the values we want to iterate through - ‘nonoil’, ‘oecd’ and ‘intermediate’. Use Snakemake’s expand() function to iteratively replace {iSubset} with each value contained in the list DATA_SUBSET Let’s start with (1). We will use an area above our Snakemake rules to store the DATA_SUBSET variable: DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # ... The capitalization of the list DATA_SUBSET is not essential. We do it to separate lists that we will iterate through from other parts of our Snakefile. This means whenever we see a capitalized name, we know it is a list that we want to iterate through. Next, we update the rule run_solow as follows: rule run_solow: input: expand(&quot;out/analysis/model_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) Now, we can clean our output folder with $ snakemake clean. If we re-run snakemake we would expect everything to run. To see if this is the case we can do a dry run. A dry run will try go through the Snakefile and print all the rules Snakemake wants to execute in order. $ snakemake --dryrun which yields the following plan: Building DAG of jobs... Job counts: count jobs 1 gen_regression_vars 1 rename_vars 1 run_solow 3 solow_model 6 [Fri Jan 11 17:00:32 2019] rule rename_vars: input: src/data/mrw.dta, src/data-management/rename_variables.R output: out/data/mrw_renamed.csv jobid: 5 [Fri Jan 11 17:00:32 2019] rule gen_regression_vars: input: out/data/mrw_renamed.csv, src/data-management/gen_reg_vars.R, src/data-specs/param_solow.json output: out/data/mrw_complete.csv jobid: 4 [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_nonoil.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_nonoil.rds jobid: 1 wildcards: iSubset=nonoil [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_oecd.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_oecd.rds jobid: 2 wildcards: iSubset=oecd [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_intermediate.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_intermediate.rds jobid: 3 wildcards: iSubset=intermediate [Fri Jan 11 17:00:32 2019] localrule run_solow: input: out/analysis/model_solow_nonoil.rds, out/analysis/model_solow_oecd.rds, out/analysis/model_solow_intermediate.rds jobid: 0 Job counts: count jobs 1 gen_regression_vars 1 rename_vars 1 run_solow 3 solow_model 6 This looks like what we want to happen. Hence, we re-run snakemake to produce all output: $ snakemake Exercise: Exploring the expand() function I So far we have estimated the basic Solow model. MRW also estimate an augmented version of the Solow model, adding human capital. The formula required to estimate the augmented model is written up in src/model-specs/model_aug_solow.json. Use the expand() function together with the estimate_ols.R script to estimate the augmented solow model on each of the three data subsets. The rule structures should look very similar to what we have done so far. Exercise: Exploring the expand function II The MRW paper contains three plots. Each of these plots use the subset of ‘intermediate’ countries. In the src/figures/ subdirectory, there are three scripts that reproduce each of the figures.3 The scripts are written in such a way that they accept exactly the same options. Using wildcards and the expand function extend the Snakefile to construct each figure. Each figure should be saved with the following name ‘out/figures/SCRIPTNAME.pdf’ 4.4 Expanding Multiple Wildcards The rules used to estimate the standard Solow model, and the augmented Solow model have very similar structure: DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # rule run_aug_solow: input: expand(&quot;out/analysis/model_aug_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) rule aug_solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_aug_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_aug_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule run_solow: input: expand(&quot;out/analysis/model_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; Add text … Ultimately the Snakfile becomes: MODELS = [ &quot;solow&quot;, &quot;aug_solow&quot; ] DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # rule estimate_models: input: expand(&quot;out/analysis/{iModel}_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) rule ols_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_{iModel}.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_{iModel}_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; &lt;...&gt; ## Other Rules below Technically there is another problem here too. Snakemake doesn’t know what values to substitute into iSubset. We focus on the Wildcard error because this is what the Snakemake error message mentions. By fixing this error, it turns out we also spell out what values to substitute into iSubset.↩ This is not entirely true, we are yet to figure out how to get the y-axis range from the original paper.↩ "],
["automatic-wildcard-specifications.html", "Chapter 5 Automatic Wildcard Specifications 5.1 The glob_wildcards Function 5.2 Further Restricting the glob_wildcards output", " Chapter 5 Automatic Wildcard Specifications So far when we have wanted to expand wildcards we have manually specified the values we want them to take. By doing so, the beginning of our Snakefile looks like this: MODELS = [ &quot;solow&quot;, &quot;aug_solow&quot; ] DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] FIGURES = [ &quot;aug_conditional_convergence&quot;, &quot;conditional_convergence&quot;, &quot;unconditional_convergence&quot; ] This is not too problematic when we only have a few values that we want the wildcard to take, but manually specifying long lists can get tedious and is prone to error. Snakemake has a built in function, glob_wildcards that will help us to remove the manual listing of values that we have above. 5.1 The glob_wildcards Function Let’s start by trying to replace the MODELS list that we manually specified with a more automated approach. The glob_wildcards function takes one input - the path of the files that we want to search combined with the part of the file name we want to extract wrapped in parentheses and then finds all files within that path. Thus, we will replace our original MODELS list with: MODELS = glob_wildcards(&quot;src/model-specs/{fname}&quot;) To see what happens, let’s add a print statement, and then execute a dry-run: MODELS = glob_wildcards(&quot;src/model-specs/{fname}&quot;) print(MODELS) then: $ snakemake --dryrun What we are interested in is the first printed lines (in white text): Wildcards(fname=[&#39;.gitkeep&#39;, &#39;model_solow.json&#39;, &#39;model_aug_cc_restr.json&#39;, &#39;model_solow_restr.json&#39;, &#39;model_cc.json&#39;, &#39;model_ucc.json&#39;, &#39;model_aug_solow_restr.json&#39;, &#39;model_aug_cc.json&#39;, &#39;model_aug_solow.json&#39;]) Here we see that all filed are returned. Compared to our original MODELS list we see three differences There are more .json files There is a .gitkeep file Each ‘fname’ ends with .json, which we did’t have earlier. is not a problem, it reflects that there is more potential analysis files that we havent manually specified. But (2) and (3) are problematic. We can remove the .gitkeep file and the .json file endings with one step: telling the glob_wildcards function to only return the part of the filename that comes before the .json. This will also mean that the .gitkeep is not returned, because this file does not have a .json ending: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;) print(MODELS) then: $ snakemake --dryrun Now the first line is: Wildcards(fname=[&#39;model_solow&#39;, &#39;model_aug_cc_restr&#39;, &#39;model_solow_restr&#39;, &#39;model_cc&#39;, &#39;model_ucc&#39;, &#39;model_aug_solow_restr&#39;, &#39;model_aug_cc&#39;, &#39;model_aug_solow&#39;]) That’s definitely an improvement. Our final step is to extract the list called fname so that we can use it like our old MODELS list. We do this as follows: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname Now if we do a dry-run we are returned the following: [&#39;model_solow&#39;, &#39;model_aug_cc_restr&#39;, &#39;model_solow_restr&#39;, &#39;model_cc&#39;, &#39;model_ucc&#39;, &#39;model_aug_solow_restr&#39;, &#39;model_aug_cc&#39;, &#39;model_aug_solow&#39;] which has the same structure as before. Now if we run snakemake: $ snakemake We see that it builds the OLS estimates of the models that we have not yet previously run4 Exercise: Exploring glob_wildcards() Use the glob_wildcards function to automate the construction of the FIGURES list. Rememeber that depending on the order of your Snakemake rules, you may need to explicitly call the rule that generates figures to run the code, i.e. snakemake make_figs. 5.2 Further Restricting the glob_wildcards output So far, we have used glob_wildcards output unchanged. Sometimes the lists that it returns might have found more files than we desire, or some of the files might be used in different ways than others. We are now going to show a simple way to filter out unwanted elements of the list that glob_wildcards returns. So far, we still have one list of wildcards that we have manually specified, DATA_SUBSET: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] FIGURES = glob_wildcards(&quot;src/figures/{fname}.json&quot;).fname Let’s start by looking at the output if we run glob_wildcards as we have before: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname DATA_SUBSET = glob_wildcards(&quot;src/data-specs/{fname}.json&quot;).fname print(DATA_SUBSET) FIGURES = glob_wildcards(&quot;src/figures/{fname}.json&quot;).fname and doing a dry run to examine the output of the print statement: $ snakemake --dryrun which yields: [&#39;param_solow&#39;, &#39;subset_oecd&#39;, &#39;subset_nonoil&#39;, &#39;subset_intermediate&#39;] In this list, the param_solow element is the odd one out. It is used in the data cleaning part, and does not contain a filter that can be applied to a data frame. The question is then how do we remove it? What we need to is complete the following steps: identify a pattern that we can use to filter out param_solow Files we want to keep all start with ‘subset’ write a function that would remove it from the list lambda x: x.startswith(&quot;subset&quot;) use this function to filter the out param_solow from DATA_SUBSET filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET)) Take the new output as a list list(filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET))) We can do this all by adding one additional line: DATA_SUBSET = glob_wildcards(&quot;src/data-specs/{fname}.json&quot;).fname DATA_SUBSET = list(filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET))) print(DATA_SUBSET) Now again doing a dry-run with snakemake --dryrun we see the first line prints out the new DATA_SUBSET list as: [&#39;subset_oecd&#39;, &#39;subset_nonoil&#39;, &#39;subset_intermediate&#39;] Which is the desired output. We can now run snakemake and see if it wants to execute any of our rules snakemake --summary and we see that it does not. Can you explain why? Running snakemake estimate_models --force will run all of the models including those that we have constructed in previous chapters.↩ "],
["adding-parameters.html", "Chapter 6 Adding Parameters", " Chapter 6 Adding Parameters Content is TBD "],
["an-all-rule.html", "Chapter 7 An all Rule", " Chapter 7 An all Rule Content is TBD "],
["logging-output-and-errors.html", "Chapter 8 Logging Output and Errors", " Chapter 8 Logging Output and Errors Content is TBD "],
["self-documenting-help.html", "Chapter 9 Self Documenting Help", " Chapter 9 Self Documenting Help Content is TBD "],
["config-files.html", "Chapter 10 Config Files", " Chapter 10 Config Files Content is TBD "],
["subworkflows-divide-and-conquer.html", "Chapter 11 Subworkflows: Divide and Conquer", " Chapter 11 Subworkflows: Divide and Conquer Content is TBD "],
["part-ii.html", "PART II", " PART II "],
["reproducible-articles-with-rmd.html", "Chapter 12 Reproducible Articles with Rmd", " Chapter 12 Reproducible Articles with Rmd Content is TBD "],
["reproducible-slides-with-rmd.html", "Chapter 13 Reproducible Slides with Rmd", " Chapter 13 Reproducible Slides with Rmd Content TBD "],
["package-dependencies-with-packrat.html", "Chapter 14 Package Dependencies with Packrat", " Chapter 14 Package Dependencies with Packrat "],
["containers.html", "Chapter 15 Containers", " Chapter 15 Containers "]
]
