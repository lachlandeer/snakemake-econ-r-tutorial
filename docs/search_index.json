[
["index.html", "Reproducible Research Workflows with Snakemake and R Prerequisites", " Reproducible Research Workflows with Snakemake and R An Extended Tutorial for Economists and Social Scientists Lachlan Deer Julian Langer 2019-02-12 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: "],
["intro.html", "Chapter 1 Motivating &amp; Rationale 1.1 A Case for Reproducibility 1.2 What is Snakemake &amp; Why Should you use it? 1.3 Why R? 1.4 Working Example: Replicating Mankiw, Romer and Weil’s 1992 QJE 1.5 The way forward", " Chapter 1 Motivating &amp; Rationale 1.1 A Case for Reproducibility 1.1.1 How far to go in the quest for reproducibility? 1.2 What is Snakemake &amp; Why Should you use it? 1.3 Why R? 1.4 Working Example: Replicating Mankiw, Romer and Weil’s 1992 QJE Throughout our tutorial we are going to use a running example to illustrate the concepts we discuss. 1.5 The way forward For the purpose of this tutorial we will focus on replicating the following aspects of the MRW paper:1 Regression Tables 1 and 2: Estimating the Textbook- and Augmented Solow Model Figure 1: Unconditional Versus Conditional Convergence To replicate these we will need to proceed as follows: Perform some data management Prepare the data before we run regressions Do some analysis. For example, run regressions for: Different subsets of data Alternative econometric specifications Turn the statistical output of the regressions into a tabular format that we can insert into a document Construct a set of graphs Integrate the tables and graphs into a paper and a set of slides (optional) We hope that these 5 steps look familiar - as they were designed to represent a simplifed workflow for an applied economist or social science researcher. Before proceeding to understanding how to use Snakemake and R to construct a reproducible workflow, the next chapter first takes a deeper dive into the a protypical way to set up a research project on our computer. Exercise: Your own project’s steps Think about a project you are working on or have worked on in the past (it may be a Bachelor or Master’s thesis or a recent / active research project). Does your project fit into the 5 steps we described above? If not, what would you modify or add to our 5 steps? (Do you think this would destroy the general principles we will encourage over the next chapters?) A complete replication using the concepts presented in this tutorial is available here↩ "],
["part-i.html", "PART I", " PART I "],
["project-organization.html", "Chapter 2 Project Organization 2.1 Project Structure I: Separating Inputs and Outputs 2.2 Project Structure II: Separating Logical Chunks of the Project 2.3 Project Structure III: Separating Input Parameters from Code", " Chapter 2 Project Organization 2.1 Project Structure I: Separating Inputs and Outputs Structuring our project and the locations of files is an important concept. Let’s look at the structure of our project’s folder. Open a terminal and change into this directory cd YOUR/PATH/TO/snakemake-econ-r-student And list the subdirectories of the main directory ls -d */ We see the following folder structure ./ |- src/ |- out/ |- log/ |- sandbox/ We recommend the following structure for any project: Root Folder src folder for input files out folder for output files a log folder to store computer logs a sandbox folder that gives us a ‘safe place’ to develop new code We discuss each of these in turn. 2.1.1 The Root Folder TBD 2.1.2 The src folder TBD 2.1.3 The out folder TBD 2.1.4 The log folder 2.1.5 Exploring the Full Structure of the MRW Replication Project Now, let’s look at all contents of this main projects directory: ls -F . We see the following folder structure ./ |- src/ |- out/ |- log/ |- sandbox/ | README.md | Snakefile Notice that there are no instances of: (i) scripts, (ii) files containing content of the paper or slides (iii) something else we haven’t thought of yet Instead, there are only two files, a README.md and a file called Snakefile. TODO: explain these two files 2.2 Project Structure II: Separating Logical Chunks of the Project As we have mentioned above, to keep our project’s structure clean, we want to keep all the computer code inside the src directory. Let’s have a look at the content of src. ls -F src/ We see the following output: ./ |src/ |- data/ |- data-management/ |- data-specs/ |- analysis/ |- model-specs/ |- lib/ |- figures/ |- tables/ The type of content we expect in each file is: TBD 2.2.1 Exploring the Structure of the MRW Replication Subdirectories We begin our exploration of the project by looking at the folders that appear to be related to the data. If we look inside the data directory ls -F src/data/ mrw.dta That is, our data/ directory contains the project’s original data set. Note that in more extensive projects, the data/ subfolder would typically have more than one data set. For example: dataset1.dta dataset2.dta dataset3.csv TBD - aside on file endings. Further, your data folder may even contain further subdirectories that organize data further ./ |src/ |- data/ |- data-provider-a/ |- dataset1.csv |- dataset2.csv |- data-provider-b/ |- dataset3.txt |- dataset4.txt If we now turn to the data-management directory, we can explore it’s contents too: ls -F src/data-management/ rename_variables.R gen_reg_vars.R TODO: meaningful filenames Note two different ways to name files Exercise: Exploring the Remaining Subdirectories TBD 2.3 Project Structure III: Separating Input Parameters from Code Next we look at the somewhat mysteriously named data-specs folder. And if we explore the folder’s contents: ls -F src/data-specs/ subset_intermediate.json subset_nonoil.json subset_oecd.json Again, the file names are somewhat meaningful on their own - they appear to be some way of subsetting data (selecting some rows). If we look inside one of these files: cat src/data-specs/subset_oecd.json { &quot;KEEP_CONDITION&quot;: &quot;oecd == 1&quot; } We see an a variable KEEP_CONDITION which is storing a string &quot;oecd == 1&quot;. TBD: Why have we done this? See below. 2.3.1 Exploring Parameter Separation in the MRW Replication Project "],
["initial-steps-with-snakemake.html", "Chapter 3 Initial Steps with Snakemake 3.1 Starting a Research Project 3.2 The Beginning of a Snakefile 3.3 Rule Structure 3.4 Our First Rule 3.5 Creating a Second Rule 3.6 Clean Rules", " Chapter 3 Initial Steps with Snakemake 3.1 Starting a Research Project We are now ready to get started working with the code and data to build a fully reproducible pipeline. In Chapter XX we described a simplified research workflow to be: Perform some data management Do some analysis Turn the output of the analysis into a tabular format Construct a set of graphs Integrate the tables and graphs into a paper and a set of slides (optional) We are going to start at the beginning with data management. Recall that we have the following files in our data management subdirectory, src/data-management: rename_variables.R gen_reg_vars.R We will need to run each of these scripts sequentially. First we want to run the script rename_variables.R to tidy up the variable names in our data set. Second, gen_reg_vars.R will create the some additional variables in our data that will be needed to run some regressions in later steps. Over the next few sections we are going to build up 2 rules, one for each file, that will execute these scripts and deliver output. 3.2 The Beginning of a Snakefile We are going to put the collection of rules that build our project into a file. We can then use the Snakemake to execute these rules and build our project. The set of rules we want to construct are going to go into the file called Snakefile - which is the name of a file that Snakemake will look into by default to execite a project. Lets open the file called Snakefile in the project’s main directory. When you open it it should look as follows: # Main Workflow - SOME PROJECT # # Contributors: YOUR NAME(S) Note that the amount of structure we have here is not totally necessary. However, good structure will make understanding easier later. Let’s go through what we see. The first lines of code are comments, to help us navigate a little and understand what we are looking at. The very first line tells us that this is a project workflow, and then tells us what the particular project is. The second line tells us who contributed to this file. This can be useful so we know who to contact with questions. You should do update the name of the project, and add your name to the list of contributors. For us, the top 2 lines becomes: # Main Workflow - MRW Replication # # Contributors: @lachlandeer, @julianlanger The next few lines are: # --- Main Build Rules --- # ## To be constructed These are more comments. We are using the # --- Something --- # notation to break up the code into logical blocks. It is in this block that we will assemble the rules on which our project will be built. 3.3 Rule Structure A Snakefile is a collection of rules that together define the order in which a project will be executed. In our Snakefile we will start to assemble rules under the # --- Main Build Rules --- # section to keep things tidy. Each rule can be thought of as a recipe that combines different inputs, such as data and and R script together to produce one or more output(s). The key components we are going to use to construct a rule are: a name for the rule, the list of inputs the list of outputs produced a shell command that tells snakemake how to combine the inputs to produce a outputs. Snakemake expects these components to be provided in a particular way so that it knows what to do with the information you provided. We are going to specify rules in the following format: rule rule_name: input: input_name1 = &quot;PATH/TO/input_one&quot;, input_name2 = &quot;PATH/TO/input_two&quot; output: output_name1 = &quot;PATH/TO/SAVE/output_one&quot;, output_name2 = &quot;PATH/TO/SAVE/output_two&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; We can have as many inputs and outputs as we need to have per rule. Each input and each output are given names, for example input_name1 which take the value to the file path and name of the file. It is important to wrap each of these paths into quotations, and to separate each of the multiple inputs and outputs with a comma. 3.4 Our First Rule 3.4.1 Constructing the Rule As mentioned above, we will start with the data management step. First script to run is rename_variables.R which is located in the data management subdirectory. This is a simple script that renames some variables for us to be easier to understand. We can then start our snakemake script by adding this script as an input: rule rule_name: input: script = &quot;src/data-management/rename_variables.R&quot;, input_name2 = &quot;PATH/TO/input_two&quot; output: output_name1 = &quot;PATH/TO/SAVE/output_one&quot;, output_name2 = &quot;PATH/TO/SAVE/output_two&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; Next, we want to add any additional inputs and also specify any outputs that the file produces. We have set up all R scripts in this example to provide us with ‘help’ so that we know what we might need to add. To find out what inputs are required and what outputs are produced, we use the --help flag when calling the file with R: $ Rscript src/data-management/rename_variables.R --help And the following output is produced: Usage: src/data-management/rename_variables.R [options] Options: -d CHARACTER, --data=CHARACTER stata dataset file name -o CHARACTER, --out=CHARACTER output file name [default = out.csv] -h, --help Show this help message and exit This suggests the script needs … We update our rename_variables as: rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;HOW TO MIX IT ALL TOGETHER&quot; Next we provide a recipe telling snakemake how to mix the inputs to create the outputs: rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data}&quot; We can now try and run snakemake to execute this rule … $ snakemake Stuff happens … 3.4.2 Analysing Output We can look into our output directory to see if anything has happened: $ ls out/data/ which yields mrw_renamed.csv Our file has been created as we expected. Try and run snakemake again $ snakemake and we see the following output: Building DAG of jobs... Nothing to be done. Why? Snakemake provides the a summary option which tells us what is going on: snakemake --summary The output is: Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_renamed.csv Thu Jan 10 20:31:08 2019 rename_vars - ok no update Explain what this tells us … Suppose we updated one of the inputs … $ touch src/data-management/rename_variables.R and then look at the summary from snakemake: $ snakemake Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_renamed.csv Thu Jan 10 20:31:08 2019 rename_vars - updated input files update pending What this means? Run snakemake to build the output: snakemake Exercise: Deleting Output Delete the output out/data/mrw_renamed.csv. Run snakemake --summary and explain the output it produced. 3.5 Creating a Second Rule The second step in our data management is to create some variables we will use in our regression analysis. The script gen_reg_vars.R in the src/data-management folder does this for us. We are going to build a rule called gen_regression_vars to do this in Snakemake. Let’s see what the script expects to be passed: $ Rscript src/data-management/gen_reg_vars.R --help Usage: src/data-management/gen_reg_vars.R [options] Options: -d CHARACTER, --data=CHARACTER a csv file name -p CHARACTER, --param=CHARACTER a file name containing model parameters -o CHARACTER, --out=CHARACTER output file name [default = out.csv] -h, --help Show this help message and exit So we need to provide: to provide the output … Let’s create this rule: rule gen_regression_vars: input: script = &quot;src/data-management/gen_reg_vars.R&quot;, data = &quot;out/data/mrw_renamed.csv&quot;, params = &quot;src/data-specs/param_solow.json&quot;, output: data = &quot;out/data/mrw_complete.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --param {input.params} \\ --out {output.data}&quot; What will Snakemake want to do next? Let’s use the summary option to see … $ snakemake --summary Building DAG of jobs... output_file date rule version log-file(s) status plan out/data/mrw_complete.csv - gen_regression_vars - missing update pending out/data/mrw_renamed.csv Fri Jan 11 13:40:07 2019 rename_vars - ok no update Explain what this means Let’s run snakemake to build our new file: $ snakemake When we look at our output directory: $ ls out/data/ mrw_complete.csv mrw_renamed.csv So we see that our data set has been built. Exercise: Creating Rules The MRW paper estimates the Solow model for three subsets of data. You need to create rules to do estimate the Solow model for each of these data sets. The R script src/analysis/estimate_ols.R will estimate a OLS model for a given dataset when you provide the necessary inputs. What inputs do you need to provide? What outputs will be produced? Write Snakemake rules to estimate the solow model for each subset of data. 3.6 Clean Rules So far, we have built up our Snakefile to: Clean data Run a regression model on different subsets of data As we continue to extend our Snakefile in the coming chapters we might want to be able to delete all of the produced outputs, and see if we can rebuild our project from the first step. One way to do this would be to go to our terminal window and enter the following command each time: $ rm -rf out/* Instead of doing this each time, we can integrate this cleaning of computer produced outputs into our Snakefile. We can create a rule called clean that stores the shell command from above: rule clean: shell: &quot;rm -rf out/*&quot; Note that this rule has no inputs or outputs. To use this rule, we enter the following into our terminal: $ snakemake clean Notice that to use the clean rule we had to call the rule name, clean, explicitly. Now if we look out the output of running the summary call with snakemake, we see the following output: snakemake --summary Building DAG of jobs... output_file date rule version log-file(s) status plan out/analysis/model_solow_subset_intermediate.rds - inter - missing update pending out/analysis/model_solow_subset_nonoil.rds - nonoil - missing update pending out/analysis/model_solow_subset_oecd.rds - oecd - missing update pending out/data/mrw_complete.csv - gen_regression_vars missing update pending out/data/mrw_renamed.csv - rename_vars missing update pending Which reveals snakemake’s plan the next time its run will be to build all outputs. Exercise: Creating Cleaning Rules So far we have written a cleaning rule that deletes everything in the out/ directory. Construct rules that would separately clean the out/data/ and out/analysis subdirectories. Why might we want to do this? "],
["pattern-rules.html", "Chapter 4 Pattern Rules 4.1 Where we are now? 4.2 Wildcards 4.3 The expand() function 4.4 Expanding Multiple Wildcards", " Chapter 4 Pattern Rules 4.1 Where we are now? Your Snakefile should look something like this: ## Snakemake - MRW Replication ## ## @yourname # --- Build Rules --- # rule solow_intermediate: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_intermediate.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_intermediate.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule solow_nonoil: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_nonoil.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_nonoil.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule solow_oecd: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_oecd.json&quot; output: model_est = &quot;out/analysis/model_solow_subset_oecd.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule gen_regression_vars: input: script = &quot;src/data-management/gen_reg_vars.R&quot;, data = &quot;out/data/mrw_renamed.csv&quot;, params = &quot;src/data-specs/param_solow.json&quot;, output: data = &quot;out/data/mrw_complete.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --param {input.params} \\ --out {output.data}&quot; rule rename_vars: input: script = &quot;src/data-management/rename_variables.R&quot;, data = &quot;src/data/mrw.dta&quot; output: data = &quot;out/data/mrw_renamed.csv&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data}&quot; # --- Clean Rules --- # rule clean: shell: &quot;rm -rf out/*&quot; This is good progress, but if we look at the solow_ rules we see that there is quite a lot of duplication: Detail the duplication here 4.2 Wildcards Ideally, we want our Snakefiles to feature the miniumum amount of duplication possible (Why?). The three solow_ rules can be collapsed into one rule if can create a variable, for example iSubset, that can iterate through the three .json files that contain the subset filters. That is, we want to create a rule solow_model that can do the work that solow_nonoil, solow_oecd and solow_intermediate currently do. In Snakemake, these variables are called wildcards. The format of this rule will be: rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; We wrapped our wildcard iSubset in curly parentheses so that Snakemake knows that we will want to substitute the name of one of the subsets into this value. This is conceptually similar to what we have done in our shell commands. We can now try and run our updated Snakefile: $ snakemake Building DAG of jobs... WorkflowError: Target rules may not contain wildcards. Please specify concrete files or a rule without wildcards. What has happened? Snakemake will not execute a rule that contains wildcards.2 What we will do is create another rule, run_solow that will not contain wildcards … rule run_solow: input: nonoil = &quot;out/analysis/model_solow_nonoil.rds&quot;, oecd = &quot;out/analysis/model_solow_oecd.rds&quot;, intermediate = &quot;out/analysis/model_solow_intermediate.rds&quot; rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; Explain what happens here… There’s more work we can do to reduce duplication. Look at the rule run_solow: rule run_solow: input: nonoil = &quot;out/analysis/model_solow_nonoil.rds&quot;, oecd = &quot;out/analysis/model_solow_oecd.rds&quot;, intermediate = &quot;out/analysis/model_solow_intermediate.rds&quot; 4.3 The expand() function Each of these inputs listed above have similar structure, with only the name of the subset of data we are using changing. We can use another feature of Snakemake to simplify this rule. Snakemake has an expand() function that can accept a wildcard and replace it with a set of specified values in an iterative manner. In our case, we want to use the expand function to accept the {iSubset} wildcard, and replace it with the values ‘nonoil’, ‘oecd’ and ‘intermediate’ one at a time. To proceed we need to do two things: Create a list, DATA_SUBSETS, that contains the values we want to iterate through - ‘nonoil’, ‘oecd’ and ‘intermediate’. Use Snakemake’s expand() function to iteratively replace {iSubset} with each value contained in the list DATA_SUBSET Let’s start with (1). We will use an area above our Snakemake rules to store the DATA_SUBSET variable: DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # ... The capitalization of the list DATA_SUBSET is not essential. We do it to separate lists that we will iterate through from other parts of our Snakefile. This means whenever we see a capitalized name, we know it is a list that we want to iterate through. Next, we update the rule run_solow as follows: rule run_solow: input: expand(&quot;out/analysis/model_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) Now, we can clean our output folder with $ snakemake clean. If we re-run snakemake we would expect everything to run. To see if this is the case we can do a dry run. A dry run will try go through the Snakefile and print all the rules Snakemake wants to execute in order. $ snakemake --dryrun which yields the following plan: Building DAG of jobs... Job counts: count jobs 1 gen_regression_vars 1 rename_vars 1 run_solow 3 solow_model 6 [Fri Jan 11 17:00:32 2019] rule rename_vars: input: src/data/mrw.dta, src/data-management/rename_variables.R output: out/data/mrw_renamed.csv jobid: 5 [Fri Jan 11 17:00:32 2019] rule gen_regression_vars: input: out/data/mrw_renamed.csv, src/data-management/gen_reg_vars.R, src/data-specs/param_solow.json output: out/data/mrw_complete.csv jobid: 4 [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_nonoil.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_nonoil.rds jobid: 1 wildcards: iSubset=nonoil [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_oecd.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_oecd.rds jobid: 2 wildcards: iSubset=oecd [Fri Jan 11 17:00:32 2019] rule solow_model: input: src/data-specs/subset_intermediate.json, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/analysis/estimate_ols_model.R output: out/analysis/model_solow_intermediate.rds jobid: 3 wildcards: iSubset=intermediate [Fri Jan 11 17:00:32 2019] localrule run_solow: input: out/analysis/model_solow_nonoil.rds, out/analysis/model_solow_oecd.rds, out/analysis/model_solow_intermediate.rds jobid: 0 Job counts: count jobs 1 gen_regression_vars 1 rename_vars 1 run_solow 3 solow_model 6 This looks like what we want to happen. Hence, we re-run snakemake to produce all output: $ snakemake Exercise: Exploring the expand() function I So far we have estimated the basic Solow model. MRW also estimate an augmented version of the Solow model, adding human capital. The formula required to estimate the augmented model is written up in src/model-specs/model_aug_solow.json. Use the expand() function together with the estimate_ols.R script to estimate the augmented solow model on each of the three data subsets. The rule structures should look very similar to what we have done so far. Exercise: Exploring the expand function II The MRW paper contains three plots. Each of these plots use the subset of ‘intermediate’ countries. In the src/figures/ subdirectory, there are three scripts that reproduce each of the figures.3 The scripts are written in such a way that they accept exactly the same options. Using wildcards and the expand function extend the Snakefile to construct each figure. Each figure should be saved with the following name ‘out/figures/SCRIPTNAME.pdf’ 4.4 Expanding Multiple Wildcards The rules used to estimate the standard Solow model, and the augmented Solow model have very similar structure: DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # rule run_aug_solow: input: expand(&quot;out/analysis/model_aug_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) rule aug_solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_aug_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_aug_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; rule run_solow: input: expand(&quot;out/analysis/model_solow_{iSubset}.rds&quot;, iSubset = DATA_SUBSET) rule solow_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_solow.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_solow_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; Add text … Ultimately the Snakfile becomes: MODELS = [ &quot;solow&quot;, &quot;aug_solow&quot; ] DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] # --- Build Rules --- # rule estimate_models: input: expand(&quot;out/analysis/{iModel}_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) rule ols_model: input: script = &quot;src/analysis/estimate_ols_model.R&quot;, data = &quot;out/data/mrw_complete.csv&quot;, model = &quot;src/model-specs/model_{iModel}.json&quot;, subset = &quot;src/data-specs/subset_{iSubset}.json&quot; output: model_est = &quot;out/analysis/model_{iModel}_{iSubset}.rds&quot;, shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est}&quot; &lt;...&gt; ## Other Rules below Technically there is another problem here too. Snakemake doesn’t know what values to substitute into iSubset. We focus on the Wildcard error because this is what the Snakemake error message mentions. By fixing this error, it turns out we also spell out what values to substitute into iSubset.↩ This is not entirely true, we are yet to figure out how to get the y-axis range from the original paper.↩ "],
["automatic-wildcard-specifications.html", "Chapter 5 Automatic Wildcard Specifications 5.1 The glob_wildcards Function 5.2 Further Restricting the glob_wildcards output", " Chapter 5 Automatic Wildcard Specifications So far when we have wanted to expand wildcards we have manually specified the values we want them to take. By doing so, the beginning of our Snakefile looks like this: MODELS = [ &quot;solow&quot;, &quot;aug_solow&quot; ] DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] FIGURES = [ &quot;aug_conditional_convergence&quot;, &quot;conditional_convergence&quot;, &quot;unconditional_convergence&quot; ] This is not too problematic when we only have a few values that we want the wildcard to take, but manually specifying long lists can get tedious and is prone to error. Snakemake has a built in function, glob_wildcards that will help us to remove the manual listing of values that we have above. 5.1 The glob_wildcards Function Let’s start by trying to replace the MODELS list that we manually specified with a more automated approach. The glob_wildcards function takes one input - the path of the files that we want to search combined with the part of the file name we want to extract wrapped in parentheses and then finds all files within that path. Thus, we will replace our original MODELS list with: MODELS = glob_wildcards(&quot;src/model-specs/{fname}&quot;) To see what happens, let’s add a print statement, and then execute a dry-run: MODELS = glob_wildcards(&quot;src/model-specs/{fname}&quot;) print(MODELS) then: $ snakemake --dryrun What we are interested in is the first printed lines (in white text): Wildcards(fname=[&#39;.gitkeep&#39;, &#39;model_solow.json&#39;, &#39;model_aug_cc_restr.json&#39;, &#39;model_solow_restr.json&#39;, &#39;model_cc.json&#39;, &#39;model_ucc.json&#39;, &#39;model_aug_solow_restr.json&#39;, &#39;model_aug_cc.json&#39;, &#39;model_aug_solow.json&#39;]) Here we see that all filed are returned. Compared to our original MODELS list we see three differences There are more .json files There is a .gitkeep file Each ‘fname’ ends with .json, which we did’t have earlier. is not a problem, it reflects that there is more potential analysis files that we havent manually specified. But (2) and (3) are problematic. We can remove the .gitkeep file and the .json file endings with one step: telling the glob_wildcards function to only return the part of the filename that comes before the .json. This will also mean that the .gitkeep is not returned, because this file does not have a .json ending: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;) print(MODELS) then: $ snakemake --dryrun Now the first line is: Wildcards(fname=[&#39;model_solow&#39;, &#39;model_aug_cc_restr&#39;, &#39;model_solow_restr&#39;, &#39;model_cc&#39;, &#39;model_ucc&#39;, &#39;model_aug_solow_restr&#39;, &#39;model_aug_cc&#39;, &#39;model_aug_solow&#39;]) That’s definitely an improvement. Our final step is to extract the list called fname so that we can use it like our old MODELS list. We do this as follows: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname Now if we do a dry-run we are returned the following: [&#39;model_solow&#39;, &#39;model_aug_cc_restr&#39;, &#39;model_solow_restr&#39;, &#39;model_cc&#39;, &#39;model_ucc&#39;, &#39;model_aug_solow_restr&#39;, &#39;model_aug_cc&#39;, &#39;model_aug_solow&#39;] which has the same structure as before. Now if we run snakemake: $ snakemake We see that it builds the OLS estimates of the models that we have not yet previously run4 Exercise: Exploring glob_wildcards() Use the glob_wildcards function to automate the construction of the FIGURES list. Rememeber that depending on the order of your Snakemake rules, you may need to explicitly call the rule that generates figures to run the code, i.e. snakemake make_figs. 5.2 Further Restricting the glob_wildcards output So far, we have used glob_wildcards output unchanged. Sometimes the lists that it returns might have found more files than we desire, or some of the files might be used in different ways than others. We are now going to show a simple way to filter out unwanted elements of the list that glob_wildcards returns. So far, we still have one list of wildcards that we have manually specified, DATA_SUBSET: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname DATA_SUBSET = [ &quot;oecd&quot;, &quot;intermediate&quot;, &quot;nonoil&quot; ] FIGURES = glob_wildcards(&quot;src/figures/{fname}.json&quot;).fname Let’s start by looking at the output if we run glob_wildcards as we have before: MODELS = glob_wildcards(&quot;src/model-specs/{fname}.json&quot;).fname DATA_SUBSET = glob_wildcards(&quot;src/data-specs/{fname}.json&quot;).fname print(DATA_SUBSET) FIGURES = glob_wildcards(&quot;src/figures/{fname}.json&quot;).fname and doing a dry run to examine the output of the print statement: $ snakemake --dryrun which yields: [&#39;param_solow&#39;, &#39;subset_oecd&#39;, &#39;subset_nonoil&#39;, &#39;subset_intermediate&#39;] In this list, the param_solow element is the odd one out. It is used in the data cleaning part, and does not contain a filter that can be applied to a data frame. The question is then how do we remove it? What we need to is complete the following steps: identify a pattern that we can use to filter out param_solow Files we want to keep all start with ‘subset’ write a function that would remove it from the list lambda x: x.startswith(&quot;subset&quot;) use this function to filter the out param_solow from DATA_SUBSET filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET)) Take the new output as a list list(filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET))) We can do this all by adding one additional line: DATA_SUBSET = glob_wildcards(&quot;src/data-specs/{fname}.json&quot;).fname DATA_SUBSET = list(filter(lambda x: x.startswith(&quot;subset&quot;), DATA_SUBSET))) print(DATA_SUBSET) Now again doing a dry-run with snakemake --dryrun we see the first line prints out the new DATA_SUBSET list as: [&#39;subset_oecd&#39;, &#39;subset_nonoil&#39;, &#39;subset_intermediate&#39;] Which is the desired output. We can now run snakemake and see if it wants to execute any of our rules snakemake --summary and we see that it does not. Can you explain why? Running snakemake estimate_models --force will run all of the models including those that we have constructed in previous chapters.↩ "],
["building-all-outputs-at-once.html", "Chapter 6 Building all outputs at once 6.1 Creating an all rule", " Chapter 6 Building all outputs at once In our analysis pipeline that we have constructed so far, we need to make two calls to snakemake to run all of our analysis: snakemake estimate_models - to estimate OLS regressions snakemake make_figs - to construct the figures Whilst this is not too time consuming, it would be desirable to only have to run Snakemake once and have all our analysis in (1) and (2) be executed. That is our next goal. So that we are all starting from the same directory structure, let’s clean our output directory, removing all estimated models and figures: $ snakemake clean Now if we list the contents of the out directory and any potential subdirectories: $ ls -R out/ we see that there are no contents remaining: out/: 6.1 Creating an all rule Out goal is to combine all the outputs from the estimate_models and make_figs rules. Let’s take a look at the structure of each of these rules so that we get a sense of what we might need to do., Here is the estimate_models rule: rule estimate_models: input: expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) And the make_figs rule: rule make_figs: input: expand(&quot;out/figures/{iFigure}.pdf&quot;, iFigure = FIGURES) These rules have a common structure: both having only an input. From other rules that we have written, we know that a rule can have multiple inputs if we name them. This suggests a way forward. We are going to create a new rule called all that contains two inputs, combining the inputs from the separate rules:5: figs, which contains the inputs from our make_figs rule models, which contains the inputs from our estimate_models rule As ever, we will have to be mindful that if we have multiple inputs, have the trailing commas located wherever one input is followed by another. Let’s put this rule as the first in our Snakefile: # --- Build Rules --- # rule all: input: figs = expand(&quot;out/figures/{iFigure}.pdf&quot;, iFigure = FIGURES), models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) Let’s check if this all rule does as desired - building all outputs. If we run snakemake --dryrun all, we get the following output: Building DAG of jobs... Job counts: count jobs 1 all 3 figures 1 gen_regression_vars 24 ols_model 1 rename_vars 30 [Tue Feb 5 16:23:01 2019] rule rename_vars: input: src/data-management/rename_variables.R, src/data/mrw.dta output: out/data/mrw_renamed.csv jobid: 29 [Tue Feb 5 16:23:01 2019] rule gen_regression_vars: input: src/data-management/gen_reg_vars.R, out/data/mrw_renamed.csv, src/data-specs/param_solow.json output: out/data/mrw_complete.csv jobid: 28 [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc.json, src/data-specs/subset_oecd.json output: out/analysis/model_aug_cc_ols_subset_oecd.rds jobid: 1 wildcards: iModel=model_aug_cc, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/data-specs/subset_oecd.json output: out/analysis/model_solow_ols_subset_oecd.rds jobid: 2 wildcards: iModel=model_solow, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow_restr.json, src/data-specs/subset_oecd.json output: out/analysis/model_solow_restr_ols_subset_oecd.rds jobid: 4 wildcards: iModel=model_solow_restr, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_cc.json, src/data-specs/subset_oecd.json output: out/analysis/model_cc_ols_subset_oecd.rds jobid: 5 wildcards: iModel=model_cc, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc_restr.json, src/data-specs/subset_intermediate.json output: out/analysis/model_aug_cc_restr_ols_subset_intermediate.rds jobid: 27 wildcards: iModel=model_aug_cc_restr, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow.json, src/data-specs/subset_intermediate.json output: out/analysis/model_aug_solow_ols_subset_intermediate.rds jobid: 9 wildcards: iModel=model_aug_solow, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow.json, src/data-specs/subset_nonoil.json output: out/analysis/model_aug_solow_ols_subset_nonoil.rds jobid: 13 wildcards: iModel=model_aug_solow, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc_restr.json, src/data-specs/subset_nonoil.json output: out/analysis/model_aug_cc_restr_ols_subset_nonoil.rds jobid: 15 wildcards: iModel=model_aug_cc_restr, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule figures: input: src/figures/aug_conditional_convergence.R, out/data/mrw_complete.csv, src/data-specs/subset_intermediate.json output: out/figures/aug_conditional_convergence.pdf jobid: 18 wildcards: iFigure=aug_conditional_convergence [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_ucc.json, src/data-specs/subset_oecd.json output: out/analysis/model_ucc_ols_subset_oecd.rds jobid: 25 wildcards: iModel=model_ucc, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow_restr.json, src/data-specs/subset_oecd.json output: out/analysis/model_aug_solow_restr_ols_subset_oecd.rds jobid: 26 wildcards: iModel=model_aug_solow_restr, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc_restr.json, src/data-specs/subset_oecd.json output: out/analysis/model_aug_cc_restr_ols_subset_oecd.rds jobid: 14 wildcards: iModel=model_aug_cc_restr, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow.json, src/data-specs/subset_oecd.json output: out/analysis/model_aug_solow_ols_subset_oecd.rds jobid: 3 wildcards: iModel=model_aug_solow, iSubset=subset_oecd [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/data-specs/subset_intermediate.json output: out/analysis/model_solow_ols_subset_intermediate.rds jobid: 7 wildcards: iModel=model_solow, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_cc.json, src/data-specs/subset_nonoil.json output: out/analysis/model_cc_ols_subset_nonoil.rds jobid: 23 wildcards: iModel=model_cc, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow_restr.json, src/data-specs/subset_intermediate.json output: out/analysis/model_solow_restr_ols_subset_intermediate.rds jobid: 10 wildcards: iModel=model_solow_restr, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc.json, src/data-specs/subset_intermediate.json output: out/analysis/model_aug_cc_ols_subset_intermediate.rds jobid: 11 wildcards: iModel=model_aug_cc, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule figures: input: src/figures/unconditional_convergence.R, out/data/mrw_complete.csv, src/data-specs/subset_intermediate.json output: out/figures/unconditional_convergence.pdf jobid: 24 wildcards: iFigure=unconditional_convergence [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_cc.json, src/data-specs/subset_intermediate.json output: out/analysis/model_cc_ols_subset_intermediate.rds jobid: 8 wildcards: iModel=model_cc, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow_restr.json, src/data-specs/subset_nonoil.json output: out/analysis/model_solow_restr_ols_subset_nonoil.rds jobid: 12 wildcards: iModel=model_solow_restr, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_solow.json, src/data-specs/subset_nonoil.json output: out/analysis/model_solow_ols_subset_nonoil.rds jobid: 16 wildcards: iModel=model_solow, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_cc.json, src/data-specs/subset_nonoil.json output: out/analysis/model_aug_cc_ols_subset_nonoil.rds jobid: 17 wildcards: iModel=model_aug_cc, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule figures: input: src/figures/conditional_convergence.R, out/data/mrw_complete.csv, src/data-specs/subset_intermediate.json output: out/figures/conditional_convergence.pdf jobid: 19 wildcards: iFigure=conditional_convergence [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_ucc.json, src/data-specs/subset_intermediate.json output: out/analysis/model_ucc_ols_subset_intermediate.rds jobid: 20 wildcards: iModel=model_ucc, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow_restr.json, src/data-specs/subset_nonoil.json output: out/analysis/model_aug_solow_restr_ols_subset_nonoil.rds jobid: 21 wildcards: iModel=model_aug_solow_restr, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_ucc.json, src/data-specs/subset_nonoil.json output: out/analysis/model_ucc_ols_subset_nonoil.rds jobid: 22 wildcards: iModel=model_ucc, iSubset=subset_nonoil [Tue Feb 5 16:23:01 2019] rule ols_model: input: src/analysis/estimate_ols_model.R, out/data/mrw_complete.csv, src/model-specs/model_aug_solow_restr.json, src/data-specs/subset_intermediate.json output: out/analysis/model_aug_solow_restr_ols_subset_intermediate.rds jobid: 6 wildcards: iModel=model_aug_solow_restr, iSubset=subset_intermediate [Tue Feb 5 16:23:01 2019] localrule all: input: out/figures/conditional_convergence.pdf, out/figures/unconditional_convergence.pdf, out/figures/aug_conditional_convergence.pdf, out/analysis/model_solow_ols_subset_oecd.rds, out/analysis/model_aug_cc_restr_ols_subset_oecd.rds, out/analysis/model_solow_restr_ols_subset_oecd.rds, out/analysis/model_cc_ols_subset_oecd.rds, out/analysis/model_ucc_ols_subset_oecd.rds, out/analysis/model_aug_solow_restr_ols_subset_oecd.rds, out/analysis/model_aug_cc_ols_subset_oecd.rds, out/analysis/model_aug_solow_ols_subset_oecd.rds, out/analysis/model_solow_ols_subset_nonoil.rds, out/analysis/model_aug_cc_restr_ols_subset_nonoil.rds, out/analysis/model_solow_restr_ols_subset_nonoil.rds, out/analysis/model_cc_ols_subset_nonoil.rds, out/analysis/model_ucc_ols_subset_nonoil.rds, out/analysis/model_aug_solow_restr_ols_subset_nonoil.rds, out/analysis/model_aug_cc_ols_subset_nonoil.rds, out/analysis/model_aug_solow_ols_subset_nonoil.rds, out/analysis/model_solow_ols_subset_intermediate.rds, out/analysis/model_aug_cc_restr_ols_subset_intermediate.rds, out/analysis/model_solow_restr_ols_subset_intermediate.rds, out/analysis/model_cc_ols_subset_intermediate.rds, out/analysis/model_ucc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_restr_ols_subset_intermediate.rds, out/analysis/model_aug_cc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_ols_subset_intermediate.rds jobid: 0 Job counts: count jobs 1 all 3 figures 1 gen_regression_vars 24 ols_model 1 rename_vars 30 The output shows that we have achieved our desired goal. The all rule builds all outputs. Notice that if you examine the order that Snakemake plans to execute the jobs that: First the data management steps are executed to prepare data This is what we would expect, as we cannot do any analysis without cleaned data The order in which the figures and regressions are executed are mixed together This is because the figures and regression outputs do not depend on each other Now we build our entire project6: $ snakemake all The name all is a convention, we could name it anything we please↩ Notice that we placed the all rule as the first rule in our Snakefile. Snakemake’s default behaviour is to build the first rule in the file, so we could instead type only snakemake and get the same result.↩ "],
["adding-parameters.html", "Chapter 7 Adding Parameters 7.1 Motivating Example: Constructing a Regression Table from OLS Results 7.2 Creating a Rule with params", " Chapter 7 Adding Parameters In our analysis pipeline so far we have always passed files to our R scripts. While we promote this practice, and wrapping important information into .json files, sometimes it seems like overkill to write a new json file to contain one line of configuration. An alternative to passing these json files is to use Snakemake’s built in params arguments, which are rule specific, to store information that we want to pass to our R Script. This goal of this chapter is to show how to use params to pass across a piece of information. 7.1 Motivating Example: Constructing a Regression Table from OLS Results So far, we have estimated a series of OLS regressions and stored there output inside the out/analysis directory. Typically once we have estimated one or more models, we want to format the output into a regression table that we can insert into a written document like a paper or set of presentation slides. In the folder src/tables/ we can see that there are a series of R scripts: $ ls src/tables/ which prints to the screen: tab01_textbook_solow.R tab03_ucc_solow.R tab05_cc_aug_solow.R tab02_augment_solow.R tab04_cc_solow.R tab06_cc_aug_solow_restr.R This shows that the example is designed to build 6 tables. Each table has it’s own script that constructs it. We will start by constructing Table 1, from tab01_textbook_solow.R Let’s have a look at what information this script expects us to pass using the help flag: Rscript src/tables/tab01_textbook_solow.R --help Usage: src/tables/tab01_textbook_solow.R [options] Options: -fp CHARACTER, --filepath=CHARACTER A directory path where models are saved -m CHARACTER, --models=CHARACTER A regex of the models to load -o CHARACTER, --out=CHARACTER output file name [default = out.tex] -h, --help Show this help message and exit From this we learn that we need to pass: --filepath, which is the directory where our OLS models are stored --models, a regular expression to tell R which models within the filepath to workwith --out, a .tex file where we want to direct the output Now we will work on constructing this rule. 7.2 Creating a Rule with params We are going to use the params option to pass across the filepath and the models regular expression into R. A sketch of the rule we want to create is: rule textbook_solow: input: script = , models = params: filepath = , model_expr = output: table = , shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table}&quot; There are two important points to notice about how we added params to our rules: params are added to the rule in a similar way to inputs and lists params are referenced identically to inputs and outputs in the shell command Now we need to decide what information needs to be entered into each line of our rule. EXPLAIN Our rule then becomes: rule textbook_solow: input: script = &quot;src/tables/tab01_textbook_solow.R&quot;, models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET)), params: filepath = &quot;out/analysis/&quot;, model_expr = &quot;model_solow*.rds&quot; output: table = &quot;out/tables/tab01_textbook_solow.tex&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table}&quot; There are two ways to run this rule: Tell snakemake to run this rule explicitly, snakemake textbook_solow Because it is not the first rule of the Snakefile it isnt run by default Add the output of this rule to the all rule. Adds creating this table to our complete analysis pipeline We prefer (2). Hence we also update the all rule as follows: rule all: input: figs = expand(&quot;out/figures/{iFigure}.pdf&quot;, iFigure = FIGURES), models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), tab01 = &quot;out/tables/tab01_textbook_solow.tex&quot; If we then do a dry run to see what Snakemake plans to do7: Building DAG of jobs... Job counts: count jobs 1 all 1 textbook_solow 2 [Tue Feb 5 17:42:59 2019] rule textbook_solow: input: src/tables/tab01_textbook_solow.R, out/analysis/model_solow_ols_subset_oecd.rds, out/analysis/model_solow_ols_subset_nonoil.rds, out/analysis/model_solow_ols_subset_intermediate.rds, out/analysis/model_aug_cc_restr_ols_subset_oecd.rds, out/analysis/model_aug_cc_restr_ols_subset_nonoil.rds, out/analysis/model_aug_cc_restr_ols_subset_intermediate.rds, out/analysis/model_solow_restr_ols_subset_oecd.rds, out/analysis/model_solow_restr_ols_subset_nonoil.rds, out/analysis/model_solow_restr_ols_subset_intermediate.rds, out/analysis/model_cc_ols_subset_oecd.rds, out/analysis/model_cc_ols_subset_nonoil.rds, out/analysis/model_cc_ols_subset_intermediate.rds, out/analysis/model_ucc_ols_subset_oecd.rds, out/analysis/model_ucc_ols_subset_nonoil.rds, out/analysis/model_ucc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_restr_ols_subset_oecd.rds, out/analysis/model_aug_solow_restr_ols_subset_nonoil.rds, out/analysis/model_aug_solow_restr_ols_subset_intermediate.rds, out/analysis/model_aug_cc_ols_subset_oecd.rds, out/analysis/model_aug_cc_ols_subset_nonoil.rds, out/analysis/model_aug_cc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_ols_subset_oecd.rds, out/analysis/model_aug_solow_ols_subset_nonoil.rds, out/analysis/model_aug_solow_ols_subset_intermediate.rds output: out/tables/tab01_textbook_solow.tex jobid: 27 [Tue Feb 5 17:42:59 2019] localrule all: input: out/figures/conditional_convergence.pdf, out/figures/unconditional_convergence.pdf, out/figures/aug_conditional_convergence.pdf, out/analysis/model_solow_ols_subset_oecd.rds, out/analysis/model_solow_ols_subset_nonoil.rds, out/analysis/model_solow_ols_subset_intermediate.rds, out/analysis/model_aug_cc_restr_ols_subset_oecd.rds, out/analysis/model_aug_cc_restr_ols_subset_nonoil.rds, out/analysis/model_aug_cc_restr_ols_subset_intermediate.rds, out/analysis/model_solow_restr_ols_subset_oecd.rds, out/analysis/model_solow_restr_ols_subset_nonoil.rds, out/analysis/model_solow_restr_ols_subset_intermediate.rds, out/analysis/model_cc_ols_subset_oecd.rds, out/analysis/model_cc_ols_subset_nonoil.rds, out/analysis/model_cc_ols_subset_intermediate.rds, out/analysis/model_ucc_ols_subset_oecd.rds, out/analysis/model_ucc_ols_subset_nonoil.rds, out/analysis/model_ucc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_restr_ols_subset_oecd.rds, out/analysis/model_aug_solow_restr_ols_subset_nonoil.rds, out/analysis/model_aug_solow_restr_ols_subset_intermediate.rds, out/analysis/model_aug_cc_ols_subset_oecd.rds, out/analysis/model_aug_cc_ols_subset_nonoil.rds, out/analysis/model_aug_cc_ols_subset_intermediate.rds, out/analysis/model_aug_solow_ols_subset_oecd.rds, out/analysis/model_aug_solow_ols_subset_nonoil.rds, out/analysis/model_aug_solow_ols_subset_intermediate.rds, out/tables/tab01_textbook_solow.tex jobid: 0 Job counts: count jobs 1 all 1 textbook_solow 2 We see that snakemake only needs to create the table from our newly created rule. Now run snakemake to build the table: $ snakemake all and when finished if we list the contents of out/tables we see our new regression table has been created: $ ls out/tables/ tab01_textbook_solow.tex Exercise: Building Table 2 Using the same rule format as above, incorporate params into a new rule called augment_solow that constructs Table 2. An alternative would be to run snakemake --summary and examine the output.↩ "],
["part-ii.html", "PART II", " PART II Some discussion before moving to the next chapter? "],
["logging-output-and-errors.html", "Chapter 8 Logging Output and Errors 8.1 Logging Output 8.2 Logging Output and Errors in One File", " Chapter 8 Logging Output and Errors 8.1 Logging Output BLAH BLAH Let’s add a log file the textbook_solow rule. rule textbook_solow: input: script = &quot;src/tables/tab01_textbook_solow.R&quot;, models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), params: filepath = &quot;out/analysis/&quot;, model_expr = &quot;model_solow*.rds&quot; output: table = &quot;out/tables/tab01_textbook_solow.tex&quot; log: &quot;logs/tables/tab01_textbook_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt; {log}&quot; Notice .Rout is a convention …, can use anything we like. If we run Snakemake on the textbook_solow rule, it will tell us there is nothing to be done. We can force Snakemake to execute a rule by adding the --force flag: $ snakemake --force textbook_solow We see that as the R script is run the printout of the LaTeX table no longer goes to the screen, it has been redirected to the log file. This can be verified by viewing the contents of the log file: cat logs/tables/tab01_textbook_solow.Rout % Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu % Date and time: Tue, Feb 05, 2019 - 06:34:51 PM \\begin{table}[!htbp] \\centering \\caption{Estimation of the Textbook Solow Model} \\label{} \\scriptsize \\begin{tabular}{@{\\extracolsep{5pt}}lcccccc} \\\\[-1.8ex]\\hline \\\\[-1.8ex] \\\\[-1.8ex] &amp; \\multicolumn{6}{c}{log(GDP per capita in 1965)} \\\\ &amp; Non-Oil &amp; Intermediate &amp; OECD &amp; Non-Oil &amp; Intermediate &amp; OECD \\\\ \\\\[-1.8ex] &amp; (1) &amp; (2) &amp; (3) &amp; (4) &amp; (5) &amp; (6)\\\\ \\hline \\\\[-1.8ex] log(I / GDP) &amp; 1.42$^{***}$ &amp; 1.32$^{***}$ &amp; 0.50 &amp; &amp; &amp; \\\\ &amp; (0.14) &amp; (0.17) &amp; (0.43) &amp; &amp; &amp; \\\\ log(n + g + $\\delta$) &amp; $-$1.99$^{***}$ &amp; $-$2.02$^{***}$ &amp; $-$0.74 &amp; &amp; &amp; \\\\ &amp; (0.56) &amp; (0.53) &amp; (0.85) &amp; &amp; &amp; \\\\ log(I / GDP) - log(n + g + $\\delta$) &amp; &amp; &amp; &amp; 1.49$^{***}$ &amp; 1.43$^{***}$ &amp; 0.55 \\\\ &amp; &amp; &amp; &amp; (0.12) &amp; (0.14) &amp; (0.37) \\\\ Constant &amp; 5.43$^{***}$ &amp; 5.35$^{***}$ &amp; 8.02$^{***}$ &amp; 6.87$^{***}$ &amp; 7.09$^{***}$ &amp; 8.62$^{***}$ \\\\ &amp; (1.58) &amp; (1.54) &amp; (2.52) &amp; (0.12) &amp; (0.15) &amp; (0.53) \\\\ \\hline \\\\[-1.8ex] Restricted Model &amp; No &amp; No &amp; No &amp; Yes &amp; Yes &amp; Yes \\\\ \\hline \\\\[-1.8ex] \\textit{N} &amp; 98 &amp; 75 &amp; 22 &amp; 98 &amp; 75 &amp; 22 \\\\ Adjusted R$^{2}$ &amp; 0.59 &amp; 0.59 &amp; 0.01 &amp; 0.59 &amp; 0.59 &amp; 0.06 \\\\ \\hline \\hline \\\\[-1.8ex] \\textit{Notes:} &amp; \\multicolumn{6}{r}{$^{***}$Significant at the 1 percent level.} \\\\ &amp; \\multicolumn{6}{r}{$^{**}$Significant at the 5 percent level.} \\\\ &amp; \\multicolumn{6}{r}{$^{*}$Significant at the 10 percent level.} \\\\ \\end{tabular} \\end{table} 8.2 Logging Output and Errors in One File Although this content has been redirected, there was still some information from the R session printed to screen. This was information about package loading. Why the separation? When we redirect using the &gt; what the bash shell is sending what’s called ‘stdout’ to the log file. stdout in this case is the table contents. The remaining information is called stderr, also known as standard error, is where BLAH.8 To integrate stderr into the same log file as the stdout we use &gt;&amp; instead of &gt;. Then our rule becomes: rule textbook_solow: input: script = &quot;src/tables/tab01_textbook_solow.R&quot;, models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), params: filepath = &quot;out/analysis/&quot;, model_expr = &quot;model_solow*.rds&quot; output: table = &quot;out/tables/tab01_textbook_solow.tex&quot; log: &quot;logs/tables/tab01_textbook_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt;&amp; {log}&quot; Now when we again run snakemake --force textbook_solow we see that no information from our R session is printed to the screen. Exercise: Logging all R Scripts Update each of the Snakemake rules to log all output to file. When finished, force the execution of the all rule, to build your entire project. HINT: Log files also accept wildcards {something}. Integrating wildcards into your log file names ensures each iteration of a rule gets a log file. We recommend the following conventions: Name the log file using the same name as the R script from which it stores the information. This makes it easier to find the log file later when debugging errors. For each subdirectory of the src folder, have a the same subdirectory in the log folder. Again this will facilitate finding the log file you want to inspect. In addition to the package loading information, if your code contains an error this is where that info will be printed.↩ "],
["self-documenting-help.html", "Chapter 9 Self Documenting Help 9.1 Our Commenting Syle 9.2 Adding Further Comments 9.3 A help Rule", " Chapter 9 Self Documenting Help As we build up our Snakemake workflow the Snakefile becomes increasingly complex. It is easy to imagine that a future version of you, or a co-author, might have difficulty understanding what each rule is doing. This chapter introduces an approach to add some comments to the Snakefile to make it easier to navigate. We also add a new help rule so that we can get a summary of the comments printed to screen. 9.1 Our Commenting Syle If we look at the Snakefile in it’s current state, we see that there are a bare minimum amount of comments already integrated. Because Snakemake is a Python library all comments must begin with one #. We then added some additional formatting of comments to create two types.9 Our first type of comment is a ‘double hash’ - ##. We use this to represent information that someone who reads our code might find helpful to build understanding of the file. For example, the head of the Snakefile contains information on the name of the workflow and the authors: ## Snakemake - MRW Replication ## ## @yourname ## Second, we have broken up the Snakefile somewhat into sections such as Dictionaries, Build Rules and Clean Rules using the # --- Something --- # notation. 9.2 Adding Further Comments The information we have added in comments so far is not really enough to help us remember much. What we want is a simple one or two line summary of what each of our rules do so that we can look back at them in the future. We are going to make comments above each rule using the ## notation. The structure will follow a common pattern: rule_name : some description For example, for the textbook_solow rule: ## textbook_solow: construct a table of regression estimates for textbook solow model rule textbook_solow: input: script = &quot;src/tables/tab01_textbook_solow.R&quot;, models = expand(&quot;out/analysis/{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET)), params: filepath = &quot;out/analysis/&quot;, model_expr = &quot;model_solow*.rds&quot; output: table = &quot;out/tables/tab01_textbook_solow.tex&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table}&quot; Exercise: Adding Comments Add some comments using our suggested style to each of the Snakemake rules we have constructed so far. 9.3 A help Rule The Snakefile is now much easier to understand when reading through it. Future you will be grateful for the effort. We can go one step further: construct a rule that prints the output of these comments to the screen. Let’s call this rule help, so that if we run snakemake help all our useful comments will be printed to screen. We usually put this help rule at the bottom of our Snakefile, so that we don’t keep bumping into it as we work. The rule has the following structure: # --- Help Rules --- # ## help : prints help comments for Snakefile rule help: input: &quot;Snakefile&quot; shell: &quot;sed -n &#39;s/^##//p&#39; {input}&quot; The rule depends on the Snakefile itself - because if the file changes, the might too. The shell comand that we use is a little confusing when we look at it the first time. Intuitively heres what it is doing: The comments we want to print are those that have the double hash notation, ##. sed is a progam that can perform text manipulations to some input We want it to find all lines starting with ## in our input file … … and print out the remainder of those lines Let’s see it in action: $ snakemake help Building DAG of jobs... Using shell: /bin/bash Provided cores: 1 Rules claiming more threads will be scaled down. Job counts: count jobs 1 help 1 [Wed Feb 6 19:13:51 2019] rule help: input: Snakefile jobid: 0 Snakemake - MRW Replication @yourname all : builds all final outputs augment_solow : construct a table of estimates for augmented solow model textbook_solow : construct a table of regression estimates for textbook solow model make_figs : builds all figures figures : recipe for constructing a figure (cannot be called) estimate_models : estimates all regressions ols_models : recipe for estimating a single regression (cannot be called) gen_regression_vars: creates variables needed to estimate a regression rename_vars : creates meaningful variable names clean : removes all content from out/ directory help : prints help comments for Snakefile [Wed Feb 6 19:13:51 2019] Finished job 0. 1 of 1 steps (100%) done We see that after the usual Snakemake output telling us what it is doing, our comments are printed to screen. Exercise: Saving help output to file Modify the help rule so that the printed content is saved in a file called HELP.txt Do notice that the exact formatting of all this help is totally arbitrary. Noone tells you that two #’s or a mix of #’s and -’s are meaningful, correct or standard ways of putting comments in a file. Our choice reflects path dependence in the way we started writing Snakefiles, and we have found them useful and persisted with our initial choice. Feel free to create your own. The only important thing is the line starts with one # so that Snakemake doesnt try and execute that line as code.↩ "],
["config-files.html", "Chapter 10 Config Files 10.1 The config.yaml filepath 10.2 Using paths from the config file", " Chapter 10 Config Files Motivation… 10.1 The config.yaml filepath In our project’s root directory we have the file config.yaml: $ ls -F config.yaml find_r_packages.sh HELP.txt install_r_packages.R logs/ out/ README.md REQUIREMENTS.txt sandbox/ Snakefile src/ If we look at the contents of config.yaml we see a collection of paths that match up to the paths in our project: $ cat config.yaml ROOT: &quot;.&quot; sub2root: &quot;../../&quot; src: &quot;src/&quot; log: &quot;logs/&quot; out: &quot;out/&quot; src_data: &quot;src/data/&quot; src_data_mgt: &quot;src/data-management/&quot; src_analysis: &quot;src/analysis/&quot; src_lib: &quot;src/lib/&quot; src_model_specs: &quot;src/model-specs/&quot; src_data_specs: &quot;src/data-specs/&quot; src_tables: &quot;src/tables/&quot; src_figures: &quot;src/figures/&quot; src_paper: &quot;src/paper/&quot; src_slides: &quot;src/slides/&quot; out_analysis: &quot;out/analysis/&quot; out_data: &quot;out/data/&quot; out_figures: &quot;out/figures/&quot; out_tables: &quot;out/tables/&quot; out_paper: &quot;out/paper/&quot; out_slides: &quot;out/slides/&quot; We can use this collection of paths to simplify the content of the Snakefile. First we must import the config.yaml file into the Snakefile. We import it using the configfile: notation, and so it’s easy for us to find, we place it at the very top of our Snakefile. ## Snakemake - MRW Replication ## ## @yourname ## # --- Importing Configuration Files --- # configfile: &quot;config.yaml&quot; # --- Dictionaries --- # &lt;...&gt; 10.2 Using paths from the config file We can now use the paths in config.yaml throughout the Snakefile. The text to the left of the colon in each line of the file is our reference to a particular path, so src_data will serve as our reference to the folder src/data/. Snakemake does not knows this path reference comes from the config file unless we instruct it to, so we reference it as config[&quot;src_data&quot;]. The path is then connected to the filename with a +. Hence we can reference the original MRW data located in src/data as config[&quot;src_data&quot;] + &quot;mrw.dta&quot; Here is the new version of the rule rename_vars using the config file to simplify the paths: ## rename_vars : creates meaningful variable names rule rename_vars: input: script = config[&quot;src_data_mgt&quot;] + &quot;rename_variables.R&quot;, data = config[&quot;src_data&quot;] + &quot;mrw.dta&quot; output: data = config[&quot;out_data&quot;] + &quot;mrw_renamed.csv&quot; log: config[&quot;out_log&quot;] + &quot;data_mgt/rename_variables.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data} \\ &gt;&amp; {log}&quot; Exercise: Using Config Files Go through the remainder of the Snakefile and replace all explicit paths with references from the config file. "],
["subworkflows-divide-and-conquer.html", "Chapter 11 Subworkflows: Divide and Conquer 11.1 Subworkflow Basics 11.2 Subworkflow dependencies", " Chapter 11 Subworkflows: Divide and Conquer motivation 11.1 Subworkflow Basics Create a Subworkflow in data-management directory. Start with empty file: $ touch src/data-management/Snakefile Add the following info to src/data-management/Snakefile: # subworkflow - data-management # # @yourname # # --- Importing Configuration Files --- # configfile: &quot;config.yaml&quot; # --- Build Rules --- # ## gen_regression_vars: creates variables needed to estimate a regression rule gen_regression_vars: input: script = config[&quot;src_data_mgt&quot;] + &quot;gen_reg_vars.R&quot;, data = config[&quot;out_data&quot;] + &quot;out/data/mrw_renamed.csv&quot;, params = config[&quot;src_data_specs&quot;] + &quot;param_solow.json&quot;, output: data = config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot; log: config[&quot;log&quot;] + &quot;data-mgt/gen_reg_vars.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --param {input.params} \\ --out {output.data} \\ &gt;&amp; {log}&quot; ## rename_vars : creates meaningful variable names rule rename_vars: input: script = config[&quot;src_data_mgt&quot;] + &quot;rename_variables.R&quot;, data = config[&quot;src_data&quot;] + &quot;mrw.dta&quot; output: data = config[&quot;out_data&quot;] + &quot;mrw_renamed.csv&quot; log: config[&quot;log&quot;] + &quot;data-mgt/rename_variables.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --out {output.data} \\ &gt;&amp; {log}&quot; Can remove these rules from Snakefile in root directory. Snakefile in root needs to know there’s another Snakefile that creates outputs that rules in it depend on: # --- Dictionaries --- # &lt;...&gt; # --- Sub Workflows --- # # only need the final outputs here subworkflow data_mgt: workdir: config[&quot;ROOT&quot;] snakefile: config[&quot;src_data_mgt&quot;] + &quot;Snakefile&quot; # --- Build Rules --- # &lt;...&gt; And we need to tell it when an input in one of our rules is created from a subworkflow. Do this by, in this case, wrapping the output with data_mgt(output_name) Then the build rules section of our root directory Snakefile becomes: &lt;...&gt; # --- Build Rules --- # ## all : builds all final outputs rule all: input: figs = expand(config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot;, iFigure = FIGURES), models = expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), tables = expand(config[&quot;out_tables&quot;] + &quot;{iTable}.tex&quot;, iTable = TABLES) ## augment_solow : construct a table of estimates for augmented solow model rule augment_solow: input: script = config[&quot;src_tables&quot;] + &quot;tab02_augment_solow.R&quot;, models = expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), params: filepath = config[&quot;out_analysis&quot;], model_expr = &quot;model_aug_solow*.rds&quot; output: table = config[&quot;out_tables&quot;] + &quot;tab02_augment_solow.tex&quot;, log: config[&quot;log&quot;] + &quot;tables/tab02_augment_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt;&amp; {log}&quot; ## textbook_solow : construct a table of regression estimates for textbook solow model rule textbook_solow: input: script = config[&quot;src_tables&quot;] + &quot;tab01_textbook_solow.R&quot;, models = expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET), params: filepath = config[&quot;out_analysis&quot;], model_expr = &quot;model_solow*.rds&quot; output: table = config[&quot;out_tables&quot;] + &quot;tab01_textbook_solow.tex&quot; log: config[&quot;log&quot;] + &quot;tables/tab01_textbook_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt;&amp; {log}&quot; ## make_figs : builds all figures rule make_figs: input: expand(config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot;, iFigure = FIGURES) ## figures : recipe for constructing a figure (cannot be called) rule figures: input: script = config[&quot;src_figures&quot;] + &quot;{iFigure}.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), subset = config[&quot;src_data_specs&quot;] + &quot;subset_intermediate.json&quot; output: fig = config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot; log: config[&quot;log&quot;]+ &quot;figures/{iFigure}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --subset {input.subset} \\ --out {output.fig} \\ &gt;&amp; {log}&quot; ## estimate_models : estimates all regressions rule estimate_models: input: expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ## ols_models : recipe for estimating a single regression (cannot be called) rule ols_model: input: script = config[&quot;src_analysis&quot;] + &quot;estimate_ols_model.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), model = config[&quot;src_model_specs&quot;] + &quot;{iModel}.json&quot;, subset = config[&quot;src_data_specs&quot;] + &quot;{iSubset}.json&quot; output: model_est = config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, log: config[&quot;log&quot;] + &quot;analysis/{iModel}_ols_{iSubset}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est} \\ &gt;&amp; {log}&quot; &lt;...&gt; Let’s examine what happens with this new Workflow. Start with a clean output directory: $ snakemake clean Now do a dry run. $ snakemake --dryrun The beginning of the output looks like: Building DAG of jobs... Executing subworkflow data_mgt. Building DAG of jobs... Job counts: count jobs 1 gen_regression_vars 1 rename_vars 2 [Mon Feb 11 22:41:42 2019] rule rename_vars: input: src/data-management/rename_variables.R, src/data/mrw.dta output: out/data/mrw_renamed.csv log: logs/data-mgt/rename_variables.Rout jobid: 1 [Mon Feb 11 22:41:42 2019] rule gen_regression_vars: input: src/data-management/gen_reg_vars.R, out/data/mrw_renamed.csv, src/data-specs/param_solow.json output: out/data/mrw_complete.csv log: logs/data-mgt/gen_reg_vars.Rout jobid: 0 Job counts: count jobs 1 gen_regression_vars 1 rename_vars 2 Executing main workflow. Job counts: count jobs 1 all 1 augment_solow 3 figures 24 ols_model 1 textbook_solow 30 Explain what has happened here. 11.2 Subworkflow dependencies We want to go further…. So create a subworkflow for analysis too, containing all rules that estimate models. Create an empty Snakefile: $ touch src/analysis/Snakefile Move analysis rules across to src/analysis/Snakefile: # subworkflow - analysis # # @yourname # # --- Importing Configuration Files --- # configfile: &quot;config.yaml&quot; # --- Build Rules --- # ## estimate_models : estimates all regressions rule estimate_models: input: expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ## ols_models : recipe for estimating a single regression (cannot be called) rule ols_model: input: script = config[&quot;src_analysis&quot;] + &quot;estimate_ols_model.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), model = config[&quot;src_model_specs&quot;] + &quot;{iModel}.json&quot;, subset = config[&quot;src_data_specs&quot;] + &quot;{iSubset}.json&quot; output: model_est = config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, log: config[&quot;log&quot;] + &quot;analysis/{iModel}_ols_{iSubset}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est} \\ &gt;&amp; {log}&quot; Following the logic in 11.1, we then update the snakefile in root by: removing the rules we copied over adding a subworkflow called analysis ensuring if we use outputs created in analysis subworkflow anywhere else, we wrap them in analysis(output) Doing (1)-(3) in our main Snakefile, suggests we update the following: (list) Let’s do it: &lt;...&gt; # --- Sub Workflows --- # subworkflow data_mgt: workdir: config[&quot;ROOT&quot;] snakefile: config[&quot;src_data_mgt&quot;] + &quot;Snakefile&quot; subworkflow analysis: workdir: config[&quot;ROOT&quot;] snakefile: config[&quot;src_analysis&quot;] + &quot;Snakefile&quot; # --- Build Rules --- # ## all : builds all final outputs rule all: input: figs = expand(config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot;, iFigure = FIGURES), models = analysis(expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ), tables = expand(config[&quot;out_tables&quot;] + &quot;{iTable}.tex&quot;, iTable = TABLES) ## augment_solow : construct a table of estimates for augmented solow model rule augment_solow: input: script = config[&quot;src_tables&quot;] + &quot;tab02_augment_solow.R&quot;, models = analysis(expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ), params: filepath = config[&quot;out_analysis&quot;], model_expr = &quot;model_aug_solow*.rds&quot; output: table = config[&quot;out_tables&quot;] + &quot;tab02_augment_solow.tex&quot;, log: config[&quot;log&quot;] + &quot;tables/tab02_augment_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt;&amp; {log}&quot; ## textbook_solow : construct a table of regression estimates for textbook solow model rule textbook_solow: input: script = config[&quot;src_tables&quot;] + &quot;tab01_textbook_solow.R&quot;, models = analysis(expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ), params: filepath = config[&quot;out_analysis&quot;], model_expr = &quot;model_solow*.rds&quot; output: table = config[&quot;out_tables&quot;] + &quot;tab01_textbook_solow.tex&quot; log: config[&quot;log&quot;] + &quot;tables/tab01_textbook_solow.Rout&quot; shell: &quot;Rscript {input.script} \\ --filepath {params.filepath} \\ --models {params.model_expr} \\ --out {output.table} \\ &gt;&amp; {log}&quot; ## make_figs : builds all figures rule make_figs: input: expand(config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot;, iFigure = FIGURES) ## figures : recipe for constructing a figure (cannot be called) rule figures: input: script = config[&quot;src_figures&quot;] + &quot;{iFigure}.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), subset = config[&quot;src_data_specs&quot;] + &quot;subset_intermediate.json&quot; output: fig = config[&quot;out_figures&quot;] + &quot;{iFigure}.pdf&quot; log: config[&quot;log&quot;]+ &quot;figures/{iFigure}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --subset {input.subset} \\ --out {output.fig} \\ &gt;&amp; {log}&quot; &lt;...&gt; Remark about dictionaries not having to be moved… Now if we again do a dry run with Snakemake let’s see what happens: Executing subworkflow analysis. Building DAG of jobs... Job counts: count jobs 24 ols_model 24 &lt;LIST OF ANALYSIS JOBS&gt; Executing subworkflow data_mgt. Building DAG of jobs... Job counts: count jobs 1 gen_regression_vars 1 rename_vars 2 &lt;LIST OF DATA-MGT JOBS&gt; Executing main workflow. Job counts: count jobs 1 all 1 augment_solow 3 figures 1 textbook_solow 6 &lt;LIST OF MAIN WORKFLOW JOBS&gt; Snakemake tells us nothing is wrong. However, if we look at the order of execution: (list) it wants to run analysis workflow before data-mgt. This should be a problem. If we try and run snakemake and execute the workflow: $ snakemake We do get the expected error: Building DAG of jobs... Executing subworkflow analysis. Building DAG of jobs... Using shell: /bin/bash Provided cores: 1 Rules claiming more threads will be scaled down. Job counts: count jobs 24 ols_model 24 Traceback (most recent call last): File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/__init__.py&quot;, line 537, in snakemake report=report) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/workflow.py&quot;, line 653, in execute success = scheduler.schedule() File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/scheduler.py&quot;, line 275, in schedule run = self.job_selector(needrun) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/scheduler.py&quot;, line 399, in job_selector c = list(map(self.job_reward, jobs)) # job rewards File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/scheduler.py&quot;, line 469, in job_reward input_size = job.inputsize File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/jobs.py&quot;, line 288, in inputsize self._inputsize = sum(f.size for f in self.input) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/jobs.py&quot;, line 288, in &lt;genexpr&gt; self._inputsize = sum(f.size for f in self.input) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 123, in wrapper return func(self, *args, **kwargs) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 138, in wrapper return func(self, *args, **kwargs) File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 286, in size return self.size_local File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 291, in size_local self.check_broken_symlink() File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 296, in check_broken_symlink if not self.exists_local and lstat(self.file): File &quot;/home/lachlan/anaconda3/lib/python3.5/site-packages/snakemake/io.py&quot;, line 29, in lstat follow_symlinks=os.stat not in os.supports_follow_symlinks) FileNotFoundError: [Errno 2] No such file or directory: &#39;/home/lachlan/teaching/snakemake-econ-r-learner/out/data/mrw_complete.csv&#39; This says that out/data/mrw_complete.csv doesn’t exist, therefore the models cannot be estimated. What’s the solution? We need to specify that the analysis subworkflow itself has a subworkflow, data_mgt, that needs to run before analysis. So we add the subworkflow data_mgt to the Snakefile in src/analysis: # subworkflow - analysis # # @yourname # # --- Importing Configuration Files --- # configfile: &quot;config.yaml&quot; # --- Sub Workflows --- # subworkflow data_mgt: workdir: config[&quot;ROOT&quot;] snakefile: config[&quot;src_data_mgt&quot;] + &quot;Snakefile&quot; # --- Build Rules --- # ## estimate_models : estimates all regressions rule estimate_models: input: expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ## ols_models : recipe for estimating a single regression (cannot be called) rule ols_model: input: script = config[&quot;src_analysis&quot;] + &quot;estimate_ols_model.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), model = config[&quot;src_model_specs&quot;] + &quot;{iModel}.json&quot;, subset = config[&quot;src_data_specs&quot;] + &quot;{iSubset}.json&quot; output: model_est = config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, log: config[&quot;log&quot;] + &quot;analysis/{iModel}_ols_{iSubset}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est} \\ &gt;&amp; {log}&quot; And we try again: $ snakemake Building DAG of jobs... Executing subworkflow data_mgt. Building DAG of jobs... Using shell: /bin/bash Provided cores: 1 Rules claiming more threads will be scaled down. Job counts: count jobs 1 gen_regression_vars 1 rename_vars 2 [Mon Feb 11 23:12:42 2019] rule rename_vars: input: src/data-management/rename_variables.R, src/data/mrw.dta output: out/data/mrw_renamed.csv log: logs/data-mgt/rename_variables.Rout jobid: 1 [Mon Feb 11 23:12:42 2019] Finished job 1. 1 of 2 steps (50%) done [Mon Feb 11 23:12:42 2019] rule gen_regression_vars: input: src/data-management/gen_reg_vars.R, src/data-specs/param_solow.json, out/data/mrw_renamed.csv output: out/data/mrw_complete.csv log: logs/data-mgt/gen_reg_vars.Rout jobid: 0 [Mon Feb 11 23:12:43 2019] Finished job 0. 2 of 2 steps (100%) done Complete log: /home/lachlan/teaching/snakemake-econ-r-learner/.snakemake/log/2019-02-11T231242.348577.snakemake.log Executing subworkflow analysis. Building DAG of jobs... Executing subworkflow data_mgt. Error: Snakefile &quot;/home/lachlan/teaching/snakemake-econ-r-learner/src/analysis/src/data-management/Snakefile&quot; not present. What has happened this time? its about the path explain why this fix works: # subworkflow - analysis # # @yourname # # --- Importing Configuration Files --- # configfile: &quot;config.yaml&quot; # --- Sub Workflows --- # subworkflow data_mgt: workdir: config[&quot;sub2root&quot;] + config[&quot;ROOT&quot;] snakefile: config[&quot;sub2root&quot;]+ config[&quot;src_data_mgt&quot;] + &quot;Snakefile&quot; # --- Build Rules --- # ## estimate_models : estimates all regressions rule estimate_models: input: expand(config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, iModel = MODELS, iSubset = DATA_SUBSET) ## ols_models : recipe for estimating a single regression (cannot be called) rule ols_model: input: script = config[&quot;src_analysis&quot;] + &quot;estimate_ols_model.R&quot;, data = data_mgt(config[&quot;out_data&quot;] + &quot;mrw_complete.csv&quot;), model = config[&quot;src_model_specs&quot;] + &quot;{iModel}.json&quot;, subset = config[&quot;src_data_specs&quot;] + &quot;{iSubset}.json&quot; output: model_est = config[&quot;out_analysis&quot;] + &quot;{iModel}_ols_{iSubset}.rds&quot;, log: config[&quot;log&quot;] + &quot;analysis/{iModel}_ols_{iSubset}.Rout&quot; shell: &quot;Rscript {input.script} \\ --data {input.data} \\ --model {input.model} \\ --subset {input.subset} \\ --out {output.model_est} \\ &gt;&amp; {log}&quot; Now if we run snakemake again: $ snakemake Our build runs from start to finish. Exercise: More Subworkflows Make two new subworkflows figs and tables to contain the rules to construct all figures and tables respectively. The end result should be only the all rule in the “Main Build Rules” section of the Snakefile of the root directory. Be sure to carefully think about properly adding subworkflows, and subworkflow dependencies. To check your new subworkflow system builds, clean the output directory and be sure after entering snakemake into the terminal that all outputs are successfully created. Guided Exercise: help rules with subworkflows With the new subworkflow system in place, examine how the output from snakemake help looks like. To bring our help rule back into shape, replace the shell command in the help rule with: find . -type f -name &#39;Snakefile&#39; | tac | xargs sed -n &#39;s/^##//p&#39; \\ &gt; {output} Explain exactly what this command is doing. (Look for help in ‘usual’ places). Next, update the inputs of the help rule so that the dependencies are correct. "],
["part-iii.html", "PART III", " PART III "],
["reproducible-articles-with-rmd.html", "Chapter 12 Reproducible Articles with Rmd", " Chapter 12 Reproducible Articles with Rmd Content is TBD "],
["reproducible-slides-with-rmd.html", "Chapter 13 Reproducible Slides with Rmd", " Chapter 13 Reproducible Slides with Rmd Content TBD "],
["package-dependencies-with-packrat.html", "Chapter 14 Package Dependencies with Packrat", " Chapter 14 Package Dependencies with Packrat "],
["containers.html", "Chapter 15 Containers", " Chapter 15 Containers "]
]
